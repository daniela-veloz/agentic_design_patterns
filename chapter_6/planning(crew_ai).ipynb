{
 "cells": [
  {
   "cell_type": "code",
   "id": "ra41ei0678c",
   "source": "# Dependencies managed via uv - see pyproject.toml\n# This notebook requires: crewai, langchain-openai, python-dotenv",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T06:02:58.752117Z",
     "start_time": "2025-12-28T06:02:49.036469Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Running the planning and writing task ##\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[35mâ•­â”€\u001B[0m\u001B[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[35m ğŸ¤– Agent Started \u001B[0m\u001B[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[35mâ”€â•®\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m                                                                                                                 \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m  \u001B[37mAgent: \u001B[0m\u001B[1;92mArticle Planner and Writer\u001B[0m                                                                              \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m                                                                                                                 \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m  \u001B[37mTask: \u001B[0m\u001B[92m1. Create a bullet-point plan for a summary on the topic: 'The importance of Reinforcement Learning in \u001B[0m  \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m  \u001B[92mAI'.\u001B[0m                                                                                                           \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m  \u001B[92m2. Write the summary based on your plan, keeping it around 200 words.\u001B[0m                                          \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ”‚\u001B[0m                                                                                                                 \u001B[35mâ”‚\u001B[0m\n",
       "\u001B[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– Agent Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Article Planner and Writer</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. Create a bullet-point plan for a summary on the topic: 'The importance of Reinforcement Learning in </span>  <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AI'.</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. Write the summary based on your plan, keeping it around 200 words.</span>                                          <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[32mâ•­â”€\u001B[0m\u001B[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[32m âœ… Agent Final Answer \u001B[0m\u001B[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[32mâ”€â•®\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m                                                                                                                 \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[37mAgent: \u001B[0m\u001B[1;92mArticle Planner and Writer\u001B[0m                                                                              \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m                                                                                                                 \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[37mFinal Answer:\u001B[0m                                                                                                  \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m### Plan\u001B[0m                                                                                                       \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m- Define Reinforcement Learning (RL) and its role in artificial intelligence.\u001B[0m                                  \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m- Discuss the key components of RL: agent, environment, actions, states, and rewards.\u001B[0m                          \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m- Highlight examples where RL has been successfully applied (e.g., gaming, robotics, healthcare).\u001B[0m              \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m- Explain how RL contributes to the development of autonomous and adaptive systems.\u001B[0m                            \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m- Mention challenges and future prospects in the field of RL.\u001B[0m                                                  \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m                                                                                                                 \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92m### Summary\u001B[0m                                                                                                    \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mReinforcement Learning (RL) is a dynamic and potent segment of machine learning, essential for advancing \u001B[0m      \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92martificial intelligence (AI). Unlike other learning algorithms, RL involves an agent that interacts with an \u001B[0m   \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92menvironment to perform specific actions, which result in states and rewards. This method is crucial for \u001B[0m       \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mprogramming agents to optimize their performance through trial and error without human intervention.\u001B[0m           \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m                                                                                                                 \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mApplications of RL are broad and impactful, encompassing areas such as gamingâ€”where DeepMind's AlphaGo \u001B[0m        \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mdefeated world championsâ€”robotics for developing more proficient autonomous robots, and healthcare, improving\u001B[0m  \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mpersonalized treatment strategies. RL's core capability to adapt and learn from new situations enables the \u001B[0m    \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mcreation of systems that improve autonomously over time, a foundational element for developing intelligent, \u001B[0m   \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92madaptive technologies.\u001B[0m                                                                                         \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m                                                                                                                 \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mHowever, the path forward for RL in AI includes challenges like the need for vast amounts of data for \u001B[0m         \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mtraining, sensitivity to initial conditions, and the complexity of designing reward systems that truly align \u001B[0m  \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mwith desired outcomes. Despite these obstacles, the future of RL promises significant advancements in \u001B[0m         \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mcreating more resilient and adaptive AI systems. The continuing evolution of RL is set to revolutionize \u001B[0m       \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m  \u001B[92mdiverse sectors by enhancing decision-making processes and operational efficiency.\u001B[0m                             \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ”‚\u001B[0m                                                                                                                 \u001B[32mâ”‚\u001B[0m\n",
       "\u001B[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Agent Final Answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Article Planner and Writer</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Plan</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Define Reinforcement Learning (RL) and its role in artificial intelligence.</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Discuss the key components of RL: agent, environment, actions, states, and rewards.</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Highlight examples where RL has been successfully applied (e.g., gaming, robotics, healthcare).</span>              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Explain how RL contributes to the development of autonomous and adaptive systems.</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Mention challenges and future prospects in the field of RL.</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">### Summary</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Reinforcement Learning (RL) is a dynamic and potent segment of machine learning, essential for advancing </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">artificial intelligence (AI). Unlike other learning algorithms, RL involves an agent that interacts with an </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">environment to perform specific actions, which result in states and rewards. This method is crucial for </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">programming agents to optimize their performance through trial and error without human intervention.</span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Applications of RL are broad and impactful, encompassing areas such as gamingâ€”where DeepMind's AlphaGo </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">defeated world championsâ€”robotics for developing more proficient autonomous robots, and healthcare, improving</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">personalized treatment strategies. RL's core capability to adapt and learn from new situations enables the </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">creation of systems that improve autonomously over time, a foundational element for developing intelligent, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">adaptive technologies.</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">However, the path forward for RL in AI includes challenges like the need for vast amounts of data for </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training, sensitivity to initial conditions, and the complexity of designing reward systems that truly align </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with desired outcomes. Despite these obstacles, the future of RL promises significant advancements in </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">creating more resilient and adaptive AI systems. The continuing evolution of RL is set to revolutionize </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">diverse sectors by enhancing decision-making processes and operational efficiency.</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "## Task Result ##\n",
      "---\n",
      "### Plan\n",
      "- Define Reinforcement Learning (RL) and its role in artificial intelligence.\n",
      "- Discuss the key components of RL: agent, environment, actions, states, and rewards.\n",
      "- Highlight examples where RL has been successfully applied (e.g., gaming, robotics, healthcare).\n",
      "- Explain how RL contributes to the development of autonomous and adaptive systems.\n",
      "- Mention challenges and future prospects in the field of RL.\n",
      "\n",
      "### Summary\n",
      "Reinforcement Learning (RL) is a dynamic and potent segment of machine learning, essential for advancing artificial intelligence (AI). Unlike other learning algorithms, RL involves an agent that interacts with an environment to perform specific actions, which result in states and rewards. This method is crucial for programming agents to optimize their performance through trial and error without human intervention.\n",
      "\n",
      "Applications of RL are broad and impactful, encompassing areas such as gamingâ€”where DeepMind's AlphaGo defeated world championsâ€”robotics for developing more proficient autonomous robots, and healthcare, improving personalized treatment strategies. RL's core capability to adapt and learn from new situations enables the creation of systems that improve autonomously over time, a foundational element for developing intelligent, adaptive technologies.\n",
      "\n",
      "However, the path forward for RL in AI includes challenges like the need for vast amounts of data for training, sensitivity to initial conditions, and the complexity of designing reward systems that truly align with desired outcomes. Despite these obstacles, the future of RL promises significant advancements in creating more resilient and adaptive AI systems. The continuing evolution of RL is set to revolutionize diverse sectors by enhancing decision-making processes and operational efficiency.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[36mâ•­â”€\u001B[0m\u001B[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[36m \u001B[0m\u001B[1;36mExecution Traces\u001B[0m\u001B[36m \u001B[0m\u001B[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[36mâ”€â•®\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m                                                                                                                 \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m  \u001B[1;36mğŸ” \u001B[0m\u001B[1;36mDetailed execution traces are available!\u001B[0m                                                                    \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m                                                                                                                 \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m  \u001B[37mView insights including:\u001B[0m                                                                                       \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m  \u001B[94m  â€¢ Agent decision-making process\u001B[0m                                                                              \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m  \u001B[94m  â€¢ Task execution flow and timing\u001B[0m                                                                             \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m  \u001B[94m  â€¢ Tool usage details\u001B[0m                                                                                         \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m                                                                                                                 \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Execution Traces</span><span style=\"color: #008080; text-decoration-color: #008080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ” Detailed execution traces are available!</span>                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">View insights including:</span>                                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Agent decision-making process</span>                                                                              <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Task execution flow and timing</span>                                                                             <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Tool usage details</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to view your execution traces? [y/N] (20s timeout): \n",
      "\n",
      "\u001B[34mâ•­â”€\u001B[0m\u001B[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[34m Tracing Preference Saved \u001B[0m\u001B[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[34mâ”€â•®\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m                                                                              \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  Info: Tracing has been disabled.                                            \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m                                                                              \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  Your preference has been saved. Future Crew/Flow executions will not        \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  collect traces.                                                             \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m                                                                              \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  To enable tracing later, do any one of these:                               \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  â€¢ Set tracing=True in your Crew/Flow code                                   \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  â€¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file               \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m  â€¢ Run: crewai traces enable                                                 \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ”‚\u001B[0m                                                                              \u001B[34mâ”‚\u001B[0m\n",
      "\u001B[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001B[0m\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env file for security\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Explicitly define the language model for clarity\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "# 2. Define a clear and focused agent\n",
    "planner_writer_agent = Agent(\n",
    "    role='Article Planner and Writer',\n",
    "    goal='Plan and then write a concise, engaging summary on a specified topic.',\n",
    "    backstory=(\n",
    "        'You are an expert technical writer and content strategist. '\n",
    "        'Your strength lies in creating a clear, actionable plan before writing, '\n",
    "        'ensuring the final summary is both informative and easy to digest.'\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm # Assign the specific LLM to the agent\n",
    ")\n",
    "\n",
    "# 3. Define a task with a more structured and specific expected output\n",
    "topic = \"The importance of Reinforcement Learning in AI\"\n",
    "high_level_task = Task(\n",
    "    description=(\n",
    "        f\"1. Create a bullet-point plan for a summary on the topic: '{topic}'.\\n\"\n",
    "        f\"2. Write the summary based on your plan, keeping it around 200 words.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A final report containing two distinct sections:\\n\\n\"\n",
    "        \"### Plan\\n\"\n",
    "        \"- A bulleted list outlining the main points of the summary.\\n\\n\"\n",
    "        \"### Summary\\n\"\n",
    "        \"- A concise and well-structured summary of the topic.\"\n",
    "    ),\n",
    "    agent=planner_writer_agent,\n",
    ")\n",
    "\n",
    "# Create the crew with a clear process\n",
    "crew = Crew(\n",
    "    agents=[planner_writer_agent],\n",
    "    tasks=[high_level_task],\n",
    "    process=Process.sequential,\n",
    ")\n",
    "\n",
    "# Execute the task\n",
    "print(\"## Running the planning and writing task ##\")\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"\\n\\n---\\n## Task Result ##\\n---\")\n",
    "print(result)"
   ],
   "id": "f2fcb3013e7043c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
