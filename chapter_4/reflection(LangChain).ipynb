{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies managed via uv - see pyproject.toml\n",
    "# This notebook requires: langchain-openai, python-dotenv"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure your API key environment variable is set (e.g., OPENAI_API_KEY)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "    print(f\"Language model initialized: {llm.model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing language model: {e}\", file=sys.stderr)\n",
    "    print(\"Please ensure your OPENAI_API_KEY is set correctly.\", file=sys.stderr)\n",
    "    sys.exit(1) # Exit if the LLM cannot be initialized\n",
    "\n",
    "\n",
    "# --- Define Chain Components ---\n",
    "\n",
    "# 1. Initial Generation: Creates the first draft of the product description.\n",
    "# The input to this chain will be a dictionary, so we update the prompt template.\n",
    "generation_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Write a short, simple product description for a new smart coffee mug.\"),\n",
    "        (\"user\", \"{product_details}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2. Critique: Evaluates the generated description and provides feedback.\n",
    "critique_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Critique the following product description based on clarity, conciseness, and appeal.\n",
    "        Provide specific suggestions for improvement.\"\"\"),\n",
    "        # This will receive 'initial_description' from the previous step.\n",
    "        (\"user\", \"Product Description to Critique:\\n{initial_description}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 3. Refinement: Rewrites the description based on the original details and the critique.\n",
    "refinement_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Based on the original product details and the following critique,\n",
    "        rewrite the product description to be more effective.\n",
    "\n",
    "        Original Product Details: {product_details}\n",
    "        Critique: {critique}\n",
    "\n",
    "        Refined Product Description:\"\"\"),\n",
    "        (\"user\", \"\") # User input is empty as the context is provided in the system message\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# --- Build the Full Reflection Chain (Refactored) ---\n",
    "# This chain is structured to be more readable and linear.\n",
    "full_reflection_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        initial_description=generation_chain\n",
    "    )\n",
    "    | RunnablePassthrough.assign(\n",
    "        critique=critique_chain\n",
    "    )\n",
    "    | refinement_chain\n",
    ")\n",
    "\n",
    "\n",
    "# --- Run the Chain ---\n",
    "async def run_reflection_example(product_details: str):\n",
    "    \"\"\"Runs the LangChain reflection example with product details.\"\"\"\n",
    "    print(f\"\\n--- Running Reflection Example for Product: '{product_details}' ---\")\n",
    "    try:\n",
    "        # The chain now expects a dictionary as input from the start.\n",
    "        final_refined_description = await full_reflection_chain.ainvoke(\n",
    "            {\"product_details\": product_details}\n",
    "        )\n",
    "        print(\"\\n--- Final Refined Product Description ---\")\n",
    "        print(final_refined_description)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during chain execution: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_product_details = \"A mug that keeps coffee hot and can be controlled by a smartphone app.\"\n",
    "    # --- Execute in Jupyter ---\n",
    "    # In Jupyter notebooks, use await directly instead of asyncio.run()\n",
    "    # since Jupyter already runs an event loop\n",
    "    await run_reflection_example(test_product_details)"
   ],
   "id": "b3f4d7ee9260b1a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
