{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-02T02:53:40.576396Z",
     "start_time": "2026-01-02T02:53:40.559476Z"
    }
   },
   "source": "from google.adk.agents import LlmAgent\nfrom google.adk.tools import agent_tool\nfrom dotenv import load_dotenv\nimport os\n\n# Load environment variables (GOOGLE_API_KEY)\nload_dotenv()\n\n# Verify API key is loaded\nif not os.getenv(\"GOOGLE_API_KEY\"):\n    print(\"WARNING: GOOGLE_API_KEY not found in environment variables!\")\n    print(\"Please add GOOGLE_API_KEY to your .env file\")\n\n# 1. A simple function tool for the core capability.\n# This follows the best practice of separating actions from reasoning.\ndef generate_image(prompt: str) -> dict:\n    \"\"\"\n    Generates an image based on a textual prompt.\n\n    Args:\n        prompt: A detailed description of the image to generate.\n\n    Returns:\n        A dictionary with the status and the generated image bytes.\n    \"\"\"\n    print(f\"TOOL: Generating image for prompt: '{prompt}'\")\n    # In a real implementation, this would call an image generation API.\n    # For this example, we return mock image data.\n    mock_image_bytes = b\"mock_image_data_for_a_cat_wearing_a_hat\"\n    return {\n        \"status\": \"success\",\n        # The tool returns the raw bytes, the agent will handle the Part creation.\n        \"image_bytes\": mock_image_bytes,\n        \"mime_type\": \"image/png\"\n    }\n\n\n# 2. Refactor the ImageGeneratorAgent into an LlmAgent.\n# It now correctly uses the input passed to it.\nimage_generator_agent = LlmAgent(\n    name=\"ImageGen\",\n    model=\"gemini-2.0-flash-exp\",\n    description=\"Generates an image based on a detailed text prompt.\",\n    instruction=(\n        \"You are an image generation specialist. Your task is to take the user's request \"\n        \"and use the `generate_image` tool to create the image. \"\n        \"The user's entire request should be used as the 'prompt' argument for the tool. \"\n        \"After the tool returns the image bytes, you MUST output the image.\"\n    ),\n    tools=[generate_image]\n)\n\n# 3. Wrap the corrected agent in an AgentTool.\n# The description is taken from the agent's description field.\nimage_tool = agent_tool.AgentTool(\n    agent=image_generator_agent\n)\n\n# 4. The parent agent remains unchanged. Its logic was correct.\nartist_agent = LlmAgent(\n    name=\"Artist\",\n    model=\"gemini-2.0-flash-exp\",\n    instruction=(\n        \"You are a creative artist. First, invent a creative and descriptive prompt for an image. \"\n        \"Then, use the `ImageGen` tool to generate the image using your prompt.\"\n    ),\n    tools=[image_tool]\n)\n\n# --- How it works now ---\n# 1. The `artist_agent` decides on a prompt, e.g., \"A photorealistic cat wearing a tiny top hat.\"\n# 2. It calls the tool: `ImageGen(input=\"A photorealistic cat wearing a tiny top hat.\")`\n#    (Note: AgentTool uses 'input' as the default parameter name for the sub-agent's query).\n# 3. The `agent_tool` invokes `image_generator_agent` with the prompt as its input.\n# 4. The `image_generator_agent` follows its instructions and calls `generate_image(prompt=\"...\")`.\n# 5. The function returns the image bytes.\n# 6. `image_generator_agent` returns the final image as its result.\n# 7. `artist_agent` receives the image result from the tool call.\n\nprint(\"Agents defined successfully!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents defined successfully!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "74j6z7o6oc3",
   "source": "# --- Execute the artist agent ---\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\nimport asyncio\n\n# Define variables for session setup\nAPP_NAME = \"image_artist_app\"\nUSER_ID = \"user_123\"\nSESSION_ID = \"session_001\"\n\n# Agent Interaction\nasync def run_artist_agent(query: str):\n    \"\"\"\n    Helper function to call the artist agent with a query.\n    \"\"\"\n    # Session and Runner setup\n    session_service = InMemorySessionService()\n    session = await session_service.create_session(\n        app_name=APP_NAME, \n        user_id=USER_ID, \n        session_id=SESSION_ID\n    )\n    runner = Runner(\n        agent=artist_agent, \n        app_name=APP_NAME, \n        session_service=session_service\n    )\n\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    \n    print(f\"\\n--- Running Artist Agent with query: '{query}' ---\\n\")\n    \n    # Use async iteration for run_async\n    async for event in runner.run_async(\n        user_id=USER_ID, \n        session_id=SESSION_ID, \n        new_message=content\n    ):\n        if event.is_final_response() and event.content:\n            final_response = \"\"\n            \n            # Extract text response\n            if hasattr(event.content, 'text') and event.content.text:\n                final_response = event.content.text\n            elif event.content.parts:\n                text_parts = [part.text for part in event.content.parts if part.text]\n                final_response = \"\".join(text_parts)\n            \n            print(\"\\n\" + \"=\" * 80)\n            print(\"Artist Agent Response:\")\n            print(\"=\" * 80)\n            print(final_response)\n            \n            # Check for image data\n            if event.content.parts:\n                for part in event.content.parts:\n                    if hasattr(part, 'inline_data') and part.inline_data:\n                        print(f\"\\nImage generated: {part.inline_data.mime_type}\")\n                        print(f\"Image size: {len(part.inline_data.data)} bytes\")\n            \n            print(\"=\" * 80)\n\n# Run the artist agent\nawait run_artist_agent(\"Create an artistic image\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T02:53:48.603641Z",
     "start_time": "2026-01-02T02:53:44.107307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Artist Agent with query: 'Create an artistic image' ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL: Generating image for prompt: 'A bioluminescent jellyfish gracefully floats through a dreamlike underwater landscape filled with towering coral structures that resemble ancient temples. Schools of tiny, glowing fish dart around, creating swirling patterns of light. The water is a deep, ethereal blue, with rays of sunlight filtering through the surface, creating an otherworldly atmosphere. The overall style should be reminiscent of a watercolor painting with a touch of surrealism.'\n",
      "\n",
      "================================================================================\n",
      "Artist Agent Response:\n",
      "================================================================================\n",
      "I have generated the image based on your prompt. The image is ready.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
